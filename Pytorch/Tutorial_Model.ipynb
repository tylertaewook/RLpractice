{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Prob: tensor([[0.1012, 0.0999, 0.1022, 0.0983, 0.0983, 0.0989, 0.0983, 0.1050, 0.0997,\n",
      "         0.0983]], grad_fn=<SoftmaxBackward>)\n",
      "Predicted Class: 7\n",
      "Predicted Class: tensor([7])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1,28,28, device=device)\n",
    "logits = model(X) # automatically calls .forward()\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1) # returns a tensor\n",
    "y_pred2 = torch.argmax(pred_probab) # returns a python value\n",
    "print(f\"Prediction Prob: {pred_probab}\") # ten dimensional tensor\n",
    "print(f\"Predicted Class: {y_pred2}\")\n",
    "print(f\"Predicted Class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 28, 28])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_image = torch.rand(3, 28, 28)\n",
    "input_image.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 784])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "flat_image.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 20])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "hidden1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU: tensor([[ 0.3693,  0.3259, -0.2324, -0.6379,  0.2806,  0.0856, -0.0410, -0.3748,\n",
      "         -0.4060, -0.1448, -0.6783,  0.1508,  0.0616, -0.6304,  0.2512, -0.5937,\n",
      "         -0.2997, -0.1858, -0.0531,  0.2384],\n",
      "        [ 0.3910, -0.1850, -0.2357, -0.5367,  0.0532, -0.3862,  0.0788, -0.3333,\n",
      "         -0.6771, -0.1157, -0.5504,  0.1849, -0.0422, -0.3601, -0.1119, -0.4723,\n",
      "         -0.1703, -0.4824, -0.3486, -0.0014],\n",
      "        [ 0.1537, -0.3205, -0.2727, -0.5765,  0.2938, -0.3194, -0.0811, -0.3998,\n",
      "         -0.3867,  0.2606, -0.7992,  0.2470, -0.0192, -0.4625,  0.2198, -0.3884,\n",
      "          0.1590, -0.2940, -0.4186,  0.3345]], grad_fn=<AddmmBackward>)\n",
      "After ReLU: tensor([[0.3693, 0.3259, 0.0000, 0.0000, 0.2806, 0.0856, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.1508, 0.0616, 0.0000, 0.2512, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.2384],\n",
      "        [0.3910, 0.0000, 0.0000, 0.0000, 0.0532, 0.0000, 0.0788, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.1849, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1537, 0.0000, 0.0000, 0.0000, 0.2938, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.2606, 0.0000, 0.2470, 0.0000, 0.0000, 0.2198, 0.0000, 0.1590, 0.0000,\n",
      "         0.0000, 0.3345]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before ReLU: {hidden1}\")\n",
    "hidden1 = nn.ReLU()(hidden1) # turns all negative values to 0\n",
    "print(f\"After ReLU: {hidden1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20,10)\n",
    ")\n",
    "input_image = torch.rand(3,28,28)\n",
    "logits = seq_modules(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model structure: {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-995843b3f728>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Layer: {name} | Size: {param.size()} | Values: {param[:2]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values: {param[:2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0278,  0.0291,  0.0266,  ...,  0.0058, -0.0090, -0.0081],\n",
      "        [ 0.0279, -0.0036,  0.0253,  ...,  0.0228,  0.0024,  0.0082],\n",
      "        [ 0.0309,  0.0141,  0.0323,  ..., -0.0239,  0.0100, -0.0240],\n",
      "        ...,\n",
      "        [-0.0141,  0.0333, -0.0043,  ..., -0.0319, -0.0081,  0.0197],\n",
      "        [-0.0137, -0.0140,  0.0050,  ..., -0.0100, -0.0151,  0.0294],\n",
      "        [ 0.0062,  0.0047, -0.0309,  ...,  0.0019,  0.0254,  0.0303]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0121,  0.0019,  0.0134, -0.0265, -0.0282, -0.0301, -0.0231,  0.0010,\n",
      "        -0.0066, -0.0007,  0.0078,  0.0014,  0.0347, -0.0310,  0.0209, -0.0168,\n",
      "         0.0147, -0.0110, -0.0097,  0.0264, -0.0242,  0.0129, -0.0314,  0.0170,\n",
      "         0.0101,  0.0185, -0.0002,  0.0124, -0.0350,  0.0284, -0.0233,  0.0282,\n",
      "        -0.0047, -0.0234, -0.0247, -0.0054,  0.0353, -0.0153,  0.0355, -0.0116,\n",
      "         0.0297, -0.0137, -0.0346,  0.0322,  0.0067, -0.0241,  0.0079, -0.0256,\n",
      "        -0.0057, -0.0003,  0.0015,  0.0356, -0.0282,  0.0235,  0.0139,  0.0336,\n",
      "         0.0058, -0.0088,  0.0020,  0.0305, -0.0100, -0.0067,  0.0038,  0.0032,\n",
      "        -0.0080,  0.0300,  0.0271,  0.0135, -0.0009, -0.0238,  0.0336,  0.0154,\n",
      "         0.0158, -0.0107,  0.0308, -0.0026, -0.0012, -0.0176, -0.0258,  0.0188,\n",
      "        -0.0276,  0.0093, -0.0297,  0.0054,  0.0184, -0.0252,  0.0145,  0.0183,\n",
      "        -0.0181, -0.0005, -0.0311,  0.0341,  0.0067, -0.0262, -0.0300,  0.0119,\n",
      "         0.0030,  0.0189, -0.0019,  0.0066, -0.0207,  0.0144, -0.0081, -0.0229,\n",
      "        -0.0328, -0.0267, -0.0099, -0.0354,  0.0135, -0.0311, -0.0002, -0.0030,\n",
      "        -0.0006,  0.0205, -0.0171,  0.0159, -0.0120,  0.0279,  0.0282, -0.0032,\n",
      "        -0.0253,  0.0269, -0.0135, -0.0223, -0.0021,  0.0253,  0.0119,  0.0205,\n",
      "         0.0077,  0.0078,  0.0004, -0.0121, -0.0093,  0.0340,  0.0173,  0.0192,\n",
      "         0.0241, -0.0258, -0.0047, -0.0254,  0.0068,  0.0212,  0.0164,  0.0316,\n",
      "         0.0225, -0.0126,  0.0053,  0.0165,  0.0304, -0.0291, -0.0007,  0.0319,\n",
      "        -0.0242, -0.0346,  0.0310,  0.0081, -0.0223,  0.0015, -0.0228,  0.0297,\n",
      "         0.0186, -0.0302, -0.0263,  0.0309,  0.0336, -0.0274, -0.0047, -0.0173,\n",
      "         0.0334, -0.0109, -0.0064, -0.0069,  0.0197, -0.0233,  0.0096, -0.0032,\n",
      "         0.0004,  0.0281,  0.0320, -0.0014, -0.0173,  0.0047, -0.0205,  0.0063,\n",
      "         0.0216,  0.0317, -0.0146,  0.0127,  0.0009, -0.0137, -0.0067, -0.0119,\n",
      "        -0.0165, -0.0218, -0.0173, -0.0236, -0.0122,  0.0121, -0.0356, -0.0161,\n",
      "        -0.0230,  0.0244,  0.0155,  0.0306, -0.0097,  0.0081, -0.0273, -0.0015,\n",
      "        -0.0012, -0.0204,  0.0054, -0.0028, -0.0125, -0.0314, -0.0111, -0.0092,\n",
      "         0.0009, -0.0282, -0.0229, -0.0077,  0.0241,  0.0190,  0.0209, -0.0326,\n",
      "         0.0262, -0.0214,  0.0057, -0.0116, -0.0325, -0.0045,  0.0227, -0.0069,\n",
      "         0.0134, -0.0119, -0.0094,  0.0107,  0.0020, -0.0172,  0.0307, -0.0246,\n",
      "        -0.0339,  0.0104, -0.0329,  0.0050,  0.0259,  0.0041, -0.0051,  0.0320,\n",
      "        -0.0039, -0.0103,  0.0266, -0.0152,  0.0182,  0.0107,  0.0016, -0.0137,\n",
      "        -0.0291,  0.0324,  0.0158, -0.0186,  0.0123,  0.0009,  0.0218, -0.0053,\n",
      "        -0.0111, -0.0107, -0.0242, -0.0120,  0.0242,  0.0165, -0.0066,  0.0265,\n",
      "        -0.0317,  0.0138, -0.0348, -0.0250, -0.0042,  0.0143,  0.0065,  0.0340,\n",
      "         0.0194,  0.0324, -0.0039,  0.0195, -0.0253, -0.0324, -0.0332, -0.0204,\n",
      "         0.0238,  0.0211,  0.0356,  0.0311,  0.0022, -0.0148,  0.0354,  0.0060,\n",
      "         0.0234,  0.0013,  0.0202, -0.0205, -0.0035, -0.0040, -0.0176, -0.0149,\n",
      "         0.0129,  0.0065,  0.0175, -0.0326, -0.0316, -0.0192, -0.0280, -0.0075,\n",
      "        -0.0041,  0.0042, -0.0295,  0.0169,  0.0317,  0.0309, -0.0252, -0.0315,\n",
      "        -0.0158, -0.0042,  0.0011, -0.0055, -0.0258,  0.0306,  0.0023, -0.0089,\n",
      "         0.0094,  0.0110,  0.0149,  0.0243,  0.0206, -0.0169, -0.0108,  0.0095,\n",
      "        -0.0263,  0.0156, -0.0057,  0.0119,  0.0261, -0.0188,  0.0116, -0.0237,\n",
      "         0.0323,  0.0118,  0.0167,  0.0029,  0.0276,  0.0066, -0.0040,  0.0139,\n",
      "         0.0021, -0.0317, -0.0052,  0.0309,  0.0011,  0.0212, -0.0304,  0.0328,\n",
      "        -0.0174,  0.0201,  0.0009, -0.0273, -0.0177, -0.0276,  0.0073,  0.0019,\n",
      "         0.0284,  0.0253,  0.0215,  0.0306,  0.0270,  0.0288, -0.0013,  0.0081,\n",
      "        -0.0219, -0.0353, -0.0032,  0.0199,  0.0101,  0.0192,  0.0028,  0.0130,\n",
      "         0.0144, -0.0182, -0.0103, -0.0287, -0.0025,  0.0336, -0.0222, -0.0153,\n",
      "        -0.0346, -0.0261, -0.0052, -0.0091, -0.0025, -0.0239, -0.0020,  0.0186,\n",
      "         0.0319, -0.0080,  0.0294, -0.0119, -0.0106,  0.0267, -0.0251,  0.0183,\n",
      "         0.0262,  0.0001,  0.0156, -0.0328,  0.0156,  0.0130,  0.0163,  0.0064,\n",
      "         0.0018, -0.0339,  0.0003,  0.0094,  0.0281, -0.0133, -0.0056, -0.0171,\n",
      "         0.0211,  0.0136, -0.0104, -0.0190,  0.0046,  0.0257, -0.0252, -0.0021,\n",
      "        -0.0259,  0.0083, -0.0307,  0.0146,  0.0348, -0.0129, -0.0329, -0.0055,\n",
      "        -0.0126,  0.0147,  0.0277,  0.0199, -0.0259, -0.0317, -0.0043, -0.0031,\n",
      "        -0.0248,  0.0172, -0.0258, -0.0029,  0.0206, -0.0184,  0.0077,  0.0173,\n",
      "        -0.0350,  0.0203,  0.0098, -0.0092,  0.0301, -0.0277, -0.0252, -0.0086,\n",
      "         0.0231,  0.0291,  0.0162,  0.0284, -0.0272, -0.0063, -0.0294, -0.0109,\n",
      "         0.0274, -0.0081,  0.0130,  0.0277, -0.0340,  0.0053, -0.0050,  0.0181,\n",
      "         0.0042,  0.0003, -0.0313,  0.0107,  0.0202,  0.0026,  0.0256,  0.0316,\n",
      "        -0.0348, -0.0185, -0.0185, -0.0231,  0.0160,  0.0120,  0.0055, -0.0157,\n",
      "         0.0316,  0.0326,  0.0029,  0.0135,  0.0025,  0.0094,  0.0022, -0.0057,\n",
      "         0.0273,  0.0171,  0.0230,  0.0226, -0.0146, -0.0273, -0.0095,  0.0337],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0149,  0.0289, -0.0045,  ...,  0.0271, -0.0401, -0.0259],\n",
      "        [-0.0162, -0.0059,  0.0361,  ...,  0.0267, -0.0126, -0.0246],\n",
      "        [-0.0166,  0.0341,  0.0432,  ..., -0.0011,  0.0066,  0.0426],\n",
      "        ...,\n",
      "        [ 0.0433,  0.0437, -0.0041,  ...,  0.0074,  0.0016, -0.0017],\n",
      "        [-0.0005,  0.0371,  0.0416,  ..., -0.0377, -0.0177, -0.0392],\n",
      "        [-0.0300, -0.0394,  0.0251,  ...,  0.0111, -0.0270, -0.0149]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 6.5822e-03,  1.1094e-02, -1.0150e-02,  2.8351e-02, -2.8457e-03,\n",
      "        -1.8444e-03, -1.6145e-02, -1.8577e-02, -2.0181e-02, -3.5097e-03,\n",
      "         1.8535e-02, -2.5005e-02, -4.2245e-02,  1.8686e-02, -4.0220e-02,\n",
      "         3.3810e-02,  1.7554e-02,  1.4115e-03, -2.4749e-02,  2.2021e-02,\n",
      "        -9.6121e-03, -4.3563e-04,  2.9163e-02,  1.1595e-02,  2.6157e-02,\n",
      "         8.3371e-03,  6.3952e-03, -1.7581e-02,  3.0919e-02, -3.4835e-03,\n",
      "        -8.7768e-03,  1.4066e-02,  8.3655e-03, -3.0676e-02, -1.2435e-02,\n",
      "        -4.2135e-02, -4.1823e-02,  2.6350e-02,  3.2420e-02,  2.8333e-02,\n",
      "         1.8517e-02,  2.9307e-02,  8.8202e-03, -2.4421e-02,  1.2707e-02,\n",
      "         2.3834e-02, -7.4682e-03,  3.0218e-03, -2.3175e-02, -3.0053e-02,\n",
      "        -2.7924e-02,  4.0084e-02,  1.5379e-02,  3.5199e-02,  8.5507e-03,\n",
      "        -1.9520e-02,  5.6703e-03, -1.3523e-02,  3.6206e-02,  3.0031e-03,\n",
      "        -9.0472e-05,  1.2780e-02,  2.8728e-02,  4.8272e-04,  3.6969e-04,\n",
      "        -8.8558e-04,  1.9989e-02,  4.2693e-02,  7.1157e-03, -2.6093e-02,\n",
      "         7.4501e-03,  2.3499e-03,  1.1159e-02, -2.5044e-02,  1.4218e-02,\n",
      "         1.5233e-02, -1.7342e-04,  3.2677e-02, -3.6057e-02,  4.3180e-02,\n",
      "         4.4063e-02, -2.0186e-02, -2.4274e-02,  3.0609e-02,  3.6129e-03,\n",
      "         2.8819e-02, -1.9717e-02, -2.3612e-02,  5.4997e-04,  3.4731e-02,\n",
      "         1.9063e-02,  2.5247e-02, -3.8755e-02, -3.4208e-02, -1.3273e-03,\n",
      "        -2.8602e-03,  1.5584e-02,  4.1022e-02,  4.1251e-03,  2.0888e-02,\n",
      "        -3.0150e-02,  1.1520e-03,  2.2140e-02,  2.0264e-02, -3.6685e-03,\n",
      "        -1.8751e-02, -1.7149e-02,  1.0611e-02,  3.3861e-02, -3.0514e-02,\n",
      "         1.6821e-02,  1.2347e-02, -9.3538e-03,  2.2736e-02, -4.1181e-02,\n",
      "         4.0391e-02,  2.0244e-02, -8.0796e-03,  1.3503e-02, -4.1380e-02,\n",
      "        -1.5092e-02, -1.7596e-03,  2.1930e-02, -2.0221e-02,  4.1980e-02,\n",
      "        -8.4755e-03,  3.6633e-02,  3.2186e-02, -2.9378e-02,  4.0760e-02,\n",
      "         3.4707e-03,  3.6475e-02, -1.2641e-02,  2.2693e-02, -2.4344e-02,\n",
      "         2.1430e-02, -7.5046e-03,  3.5812e-02,  2.9226e-02, -2.8068e-02,\n",
      "        -1.9209e-02, -2.2564e-02, -3.5301e-02, -4.2026e-02, -7.4490e-03,\n",
      "        -4.1954e-02,  3.5138e-02, -2.1119e-02,  6.9574e-03,  1.5890e-03,\n",
      "        -1.0377e-02, -2.7384e-02,  3.6623e-02,  2.6512e-02,  1.2707e-02,\n",
      "        -3.3961e-02, -2.2608e-02, -2.6510e-02,  3.8323e-02,  2.3143e-02,\n",
      "        -1.3102e-02,  3.5298e-02,  9.6125e-03,  1.6494e-02, -1.7595e-02,\n",
      "         9.9386e-03,  1.1565e-02, -7.6648e-03,  4.3821e-02,  2.7286e-02,\n",
      "         1.8103e-02,  1.9408e-02, -3.2900e-02,  4.3428e-02, -4.2477e-02,\n",
      "        -2.7175e-02,  1.4528e-02, -1.2507e-02,  2.3780e-02, -1.6117e-02,\n",
      "         3.8190e-03,  2.8663e-02, -1.8461e-03,  1.9914e-02, -3.7430e-03,\n",
      "         1.3329e-02,  3.0806e-03,  2.4522e-02,  4.0618e-02,  3.2349e-02,\n",
      "        -4.7322e-03,  1.7237e-02,  1.1281e-02, -6.7469e-03,  8.2828e-03,\n",
      "        -1.6220e-02,  1.5322e-02, -1.4757e-02, -1.0622e-02,  4.1922e-02,\n",
      "        -7.0065e-03,  3.7697e-02,  6.5540e-03,  2.9254e-02,  1.5593e-02,\n",
      "        -7.2116e-03, -6.2606e-04,  2.5052e-02,  2.1431e-02, -1.7814e-02,\n",
      "        -3.7590e-02, -3.3860e-02,  3.7523e-02,  3.9631e-02,  2.4966e-02,\n",
      "         4.1340e-02,  2.1509e-02, -4.0437e-02, -2.8578e-02, -4.3862e-02,\n",
      "         3.9258e-02, -8.1701e-03,  2.5941e-02, -4.2076e-02, -2.9495e-02,\n",
      "         3.3388e-03,  3.7840e-02, -2.6079e-02,  1.4376e-05, -1.8137e-02,\n",
      "         2.2736e-02,  3.0852e-02, -2.5660e-02,  2.8302e-02,  1.5171e-02,\n",
      "         2.3872e-02, -4.3039e-02,  3.0097e-02,  1.0848e-02, -4.2418e-02,\n",
      "         3.9524e-02,  1.5528e-02,  2.1545e-02,  7.3387e-03, -3.3081e-02,\n",
      "         3.2548e-02, -3.3434e-02, -2.9552e-02,  3.7751e-02,  3.8511e-02,\n",
      "         4.4341e-03, -2.3886e-02, -2.9432e-02, -4.9496e-03, -3.4092e-02,\n",
      "         6.5107e-04, -4.2662e-02, -2.6082e-02,  4.3831e-02,  9.3260e-03,\n",
      "        -3.8779e-02,  3.4132e-02, -1.5429e-02, -2.4592e-02, -1.5296e-02,\n",
      "         3.7771e-02, -3.4363e-03, -1.1996e-02,  3.1124e-02, -3.2370e-02,\n",
      "         9.7003e-03, -1.5955e-02,  4.1015e-02, -2.0295e-02,  1.6964e-02,\n",
      "        -2.3358e-02,  3.4623e-02,  3.4789e-02,  1.2551e-02, -1.0637e-02,\n",
      "         3.9056e-02,  3.7347e-02,  3.7812e-02,  2.2915e-02, -3.0525e-02,\n",
      "         2.2828e-02, -3.3618e-02, -2.2940e-02,  2.4187e-02,  3.8256e-02,\n",
      "        -6.5416e-03,  2.1083e-02, -9.5872e-03,  3.6122e-03,  3.3645e-02,\n",
      "        -3.1636e-02,  2.1076e-02,  3.2972e-02, -1.3639e-02,  3.7813e-02,\n",
      "        -2.6648e-02, -3.1990e-02,  6.4510e-04, -4.1504e-03,  2.6232e-02,\n",
      "        -3.9581e-02,  2.7849e-02,  3.0073e-02, -1.4060e-02, -1.6549e-02,\n",
      "         3.7310e-03, -2.8216e-03, -1.7547e-02, -2.6698e-02,  2.4952e-02,\n",
      "         4.3966e-03,  3.0439e-02,  5.0741e-03, -2.0849e-02,  3.4594e-02,\n",
      "         5.1577e-03,  1.5808e-02,  4.1716e-02,  1.9022e-02, -3.5875e-02,\n",
      "         1.0237e-03, -6.0286e-03, -1.6613e-02, -2.9661e-02,  2.4785e-02,\n",
      "         2.0031e-02,  1.0179e-02, -2.4545e-02, -1.2911e-02, -1.8002e-02,\n",
      "         2.8220e-02, -4.1016e-02, -2.3442e-02, -7.4296e-03, -4.0432e-02,\n",
      "        -2.6239e-03,  3.5426e-02, -1.5915e-02, -4.2987e-02,  4.0520e-02,\n",
      "        -4.5968e-03, -3.0038e-02, -1.0493e-03,  3.5601e-02,  1.2463e-02,\n",
      "        -1.9004e-02,  2.2624e-03,  8.6799e-03,  2.9979e-02, -4.4710e-03,\n",
      "         1.5920e-02, -3.8122e-02, -3.6451e-02,  1.5275e-02,  2.9914e-02,\n",
      "        -3.3142e-02, -1.7957e-02,  3.5152e-02, -1.0357e-02, -4.0992e-03,\n",
      "         3.8759e-02, -3.5802e-02,  1.1311e-02,  4.0137e-02,  3.0609e-02,\n",
      "         3.5389e-02, -4.5071e-03,  2.0207e-02,  1.7311e-03, -2.8831e-02,\n",
      "         2.3856e-02, -3.5927e-02, -1.7978e-02, -3.9958e-02, -1.4275e-02,\n",
      "         1.3252e-02, -1.4986e-02,  3.8930e-02, -3.3705e-02, -1.3533e-03,\n",
      "         2.4694e-02,  3.2330e-02, -2.4624e-02, -2.4038e-02,  5.3830e-03,\n",
      "         2.0816e-02, -3.1229e-02, -3.7015e-02, -4.2845e-02,  2.2272e-02,\n",
      "         4.1080e-02, -3.4398e-02, -4.2890e-02,  2.9857e-02, -2.2505e-02,\n",
      "         3.3590e-02,  1.7143e-02, -3.3849e-02, -1.2431e-02,  3.9978e-02,\n",
      "         2.7454e-02, -3.1438e-02, -2.7632e-03,  5.8926e-03, -9.5425e-04,\n",
      "         9.2076e-03,  2.2241e-02,  3.8649e-02, -1.9098e-02, -2.5328e-02,\n",
      "         5.0347e-03, -3.3678e-03,  3.5750e-02,  3.9228e-02,  3.6159e-02,\n",
      "        -1.4161e-02, -2.1880e-02, -3.5028e-02,  3.2042e-02, -4.8743e-03,\n",
      "        -3.6898e-02,  2.5323e-02, -1.8301e-02, -7.9757e-03,  3.1041e-04,\n",
      "         9.4737e-03,  1.3835e-02, -2.3478e-02,  2.6207e-03, -4.0705e-02,\n",
      "        -1.6229e-03, -2.4812e-02,  3.9117e-02,  1.2261e-02,  3.3632e-03,\n",
      "         7.1683e-03, -3.2413e-02,  7.4948e-03, -2.4252e-04,  6.2844e-03,\n",
      "        -3.1437e-02, -1.8086e-02, -2.8836e-02,  2.4930e-02,  2.7501e-02,\n",
      "        -4.2622e-03,  3.3934e-02, -1.5593e-02, -2.1618e-03,  2.4355e-02,\n",
      "         3.3563e-02, -2.2372e-02, -2.1604e-02,  1.8906e-02,  1.3422e-02,\n",
      "         4.3744e-02, -2.4322e-02, -3.9666e-03, -1.6307e-02,  2.9555e-02,\n",
      "         2.3744e-02, -1.3293e-02, -4.6152e-03,  6.4605e-03,  2.6343e-02,\n",
      "        -1.4846e-02, -2.2513e-02, -3.1899e-02,  3.6083e-02, -1.9501e-02,\n",
      "        -5.7545e-03,  4.4794e-03,  1.4890e-03,  2.8448e-02,  6.5914e-04,\n",
      "        -1.7929e-02, -2.8840e-02, -2.6012e-02, -3.6472e-02, -3.1440e-03,\n",
      "         3.8176e-02,  4.4876e-03,  2.2263e-02, -1.5317e-03, -3.3941e-02,\n",
      "         7.3034e-03, -4.3686e-02,  4.1140e-02, -3.5458e-02,  2.7810e-03,\n",
      "         3.0203e-02, -7.7658e-04,  2.4273e-02, -3.5329e-02, -2.3609e-02,\n",
      "        -1.5610e-03,  9.5975e-03,  3.7548e-02, -2.6671e-02, -1.9009e-02,\n",
      "        -4.2790e-02,  1.0016e-02,  1.5423e-02,  2.6790e-02, -3.0017e-02,\n",
      "         1.0545e-02,  2.5193e-02], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0126,  0.0371, -0.0018,  ..., -0.0058,  0.0397, -0.0353],\n",
      "        [ 0.0270, -0.0360, -0.0246,  ...,  0.0257,  0.0354, -0.0069],\n",
      "        [ 0.0266, -0.0007, -0.0364,  ...,  0.0082, -0.0106, -0.0408],\n",
      "        ...,\n",
      "        [ 0.0172,  0.0349, -0.0343,  ...,  0.0404, -0.0098,  0.0019],\n",
      "        [ 0.0248,  0.0366,  0.0037,  ..., -0.0276, -0.0436, -0.0224],\n",
      "        [ 0.0407, -0.0066,  0.0055,  ...,  0.0235,  0.0185, -0.0004]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0393, -0.0134,  0.0366, -0.0367, -0.0228,  0.0110, -0.0160, -0.0060,\n",
      "         0.0111, -0.0381], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in model.parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_relu_stack.0.weight\n",
      "linear_relu_stack.0.bias\n",
      "linear_relu_stack.2.weight\n",
      "linear_relu_stack.2.bias\n",
      "linear_relu_stack.4.weight\n",
      "linear_relu_stack.4.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
